{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## **Clone the repo and set the wandb key**","metadata":{}},{"cell_type":"code","source":"!rm -rf LLM-abductive-event-reasoning\n!git clone https://github.com/irenebartolini02/LLM-abductive-event-reasoning.git\n\n\n!pip install -r LLM-abductive-event-reasoning/requirements.txt -q\n\n\nfrom kaggle_secrets import UserSecretsClient\nimport wandb\n\n# Inizializza il client\nuser_secrets = UserSecretsClient()\n\n# Leggi la tua API key W&B\napi_key = user_secrets.get_secret(\"WANDB_API_KEY\")\n\nprint(\"WANDB_API_KEY trovata:\", api_key is not None)\n\n# Imposta per wandb\nimport os\nos.environ[\"WANDB_API_KEY\"] = api_key","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T17:27:49.895799Z","iopub.execute_input":"2026-01-31T17:27:49.896563Z","iopub.status.idle":"2026-01-31T17:27:56.861387Z","shell.execute_reply.started":"2026-01-31T17:27:49.896531Z","shell.execute_reply":"2026-01-31T17:27:56.860660Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'LLM-abductive-event-reasoning'...\nremote: Enumerating objects: 335, done.\u001b[K\nremote: Counting objects: 100% (135/135), done.\u001b[K\nremote: Compressing objects: 100% (94/94), done.\u001b[K\nremote: Total 335 (delta 66), reused 103 (delta 39), pack-reused 200 (from 1)\u001b[K\nReceiving objects: 100% (335/335), 33.66 MiB | 19.51 MiB/s, done.\nResolving deltas: 100% (166/166), done.\nWANDB_API_KEY trovata: True\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"## **Clone the dataset**","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/sooo66/semeval2026-task12-dataset.git\n!ls semeval2026-task12-dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T16:48:16.869416Z","iopub.execute_input":"2026-01-31T16:48:16.869814Z","iopub.status.idle":"2026-01-31T16:48:19.109061Z","shell.execute_reply.started":"2026-01-31T16:48:16.869784Z","shell.execute_reply":"2026-01-31T16:48:19.108370Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'semeval2026-task12-dataset'...\nremote: Enumerating objects: 63, done.\u001b[K\nremote: Counting objects: 100% (63/63), done.\u001b[K\nremote: Compressing objects: 100% (48/48), done.\u001b[K\nremote: Total 63 (delta 27), reused 46 (delta 13), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (63/63), 6.71 MiB | 22.25 MiB/s, done.\nResolving deltas: 100% (27/27), done.\ndev_data   sample_data\t\t\t   test_data\nREADME.md  semeval2026-task12-dataset-old  train_data\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## **Run the evaluation loop**","metadata":{}},{"cell_type":"code","source":"# Run the evaluation loop\n# output_file acts also as a checkpoint, so delete it if you want to start from 0\n!python LLM-abductive-event-reasoning/run_eval.py \\\n    --dataset_path \"/kaggle/working/semeval2026-task12-dataset\" \\\n    --output_file \"/kaggle/working/checkpoints/eval_results.jsonl\" \\\n    --search_steps 1 \\\n    --use_wandb \\\n    #--use_debug","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T17:28:01.967567Z","iopub.execute_input":"2026-01-31T17:28:01.968334Z","iopub.status.idle":"2026-01-31T17:32:21.202223Z","shell.execute_reply.started":"2026-01-31T17:28:01.968302Z","shell.execute_reply":"2026-01-31T17:32:21.201044Z"}},"outputs":[{"name":"stdout","text":"2026-01-31 17:28:07.765322: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1769880487.787453     686 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1769880487.794068     686 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1769880487.811160     686 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769880487.811191     686 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769880487.811196     686 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769880487.811201     686 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msimonecolu\u001b[0m (\u001b[33msimonecolu-politecnico-di-torino\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run 6h1yeitp (0.2s)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run 6h1yeitp (0.2s)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m setting up run 6h1yeitp (0.2s)\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.2\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20260131_172813-6h1yeitp\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mQwen 2.5/7B\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/simonecolu-politecnico-di-torino/Agentic-Causal-Reasoning\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/simonecolu-politecnico-di-torino/Agentic-Causal-Reasoning/runs/6h1yeitp\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Detected [agents] in use.\n\u001b[34m\u001b[1mwandb\u001b[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.\n\u001b[34m\u001b[1mwandb\u001b[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/\nLoading Model: Qwen/Qwen2.5-7B-Instruct\nModel loaded on: cuda:0\nModel loaded successfully\n\nLoading Data from /kaggle/working/semeval2026-task12-dataset...\nData loaded successfully\n\nLoading Embedder: BAAI/bge-base-en-v1.5...\nEmbedder loaded succesfully\n\nLoading Reranker: cross-encoder/ms-marco-MiniLM-L-6-v2...\nReranker loaded successfully\n\nInitializing RAG Chain...\nIndexing Documents...\nIndexing completed for 36 topics.\nRecupero checkpoint da /kaggle/working/checkpoints/eval_results.jsonl...\nRestored 15 items.\nStarting Evaluation Loop...\n  4%|‚ñà‚ñä                                        | 17/400 [01:54<50:33,  7.92s/it]^C\n  4%|‚ñà‚ñã                                      | 17/400 [02:47<1:02:55,  9.86s/it]\nTraceback (most recent call last):\n  File \"/kaggle/working/LLM-abductive-event-reasoning/run_eval.py\", line 288, in <module>\n    main()\n  File \"/kaggle/working/LLM-abductive-event-reasoning/run_eval.py\", line 199, in main\n    causal_response_parsed = reasoner_agent(model,tokenizer,final_context,entry)\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/kaggle/working/LLM-abductive-event-reasoning/agents/reasoner.py\", line 19, in reasoner_agent\n    outputs = model.generate(\n              ^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\", line 2564, in generate\n    result = decoding_method(\n             ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\", line 2787, in _sample\n    outputs = model_forward(**model_inputs, return_dict=True)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\", line 918, in wrapper\n    output = func(self, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py\", line 449, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n                                       ^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\", line 1064, in wrapper\n    outputs = func(self, *args, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py\", line 384, in forward\n    hidden_states = decoder_layer(\n                    ^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py\", line 94, in __call__\n    return super().__call__(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\", line 172, in wrapped_func\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py\", line 249, in forward\n    hidden_states = self.mlp(hidden_states)\n                    ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py\", line 46, in forward\n    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nKeyboardInterrupt\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}